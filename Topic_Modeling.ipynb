{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RDGopal/IB9LQ0-GenAI/blob/main/Topic_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE8bZiPYuFd-"
      },
      "source": [
        "# Topic Modeling with LDA\n",
        "Topic Modeling is a type of statistical modeling for discovering the abstract \"topics\" that occur in a collection of documents. It is a frequent technique in text mining for uncovering hidden semantic structures in a text body. This process is useful in various applications like organizing large archives of texts, summarizing information, and aiding in understanding the main themes of texts without reading them in full.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install Packages"
      ],
      "metadata": {
        "id": "Ty2e-f4HGAvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "BcIQCBN6gOMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select Runtime-Restart session after installing gensim**"
      ],
      "metadata": {
        "id": "g6rgmvuel9bV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install numpy==1.24.3"
      ],
      "metadata": {
        "id": "_A-741qdf7tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95lCXgr3wqu1"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, SnowballStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQhxTxC-w_gl"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Read and Preprocess Data"
      ],
      "metadata": {
        "id": "OE8zIH_aGGT6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dZIXC-il2WQ"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess the data\n",
        "def preprocess_texts(documents):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    preprocessed_texts = []\n",
        "    for text in documents:\n",
        "        text = text.lower()\n",
        "        tokens = nltk.word_tokenize(text)\n",
        "        tokens = [token for token in tokens if token not in stop_words and token.isalpha()]\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "        preprocessed_texts.append(tokens)  # Append list of tokens directly, without joining them into a string\n",
        "\n",
        "    return preprocessed_texts\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Qz9xVyCbAY8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('fakenews.csv',nrows=500)"
      ],
      "metadata": {
        "id": "ysli7eIXzy4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = preprocess_texts(df['text'])\n",
        "dictionary = Dictionary(texts)\n",
        "\n",
        "# Create a document-term matrix\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ],
      "metadata": {
        "id": "hjGvkSWEBmUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LDA"
      ],
      "metadata": {
        "id": "aTUOu2cMGLY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF1aLJtaCHTb"
      },
      "outputs": [],
      "source": [
        "# Set parameters\n",
        "num_topics = 2\n",
        "passes = 10\n",
        "\n",
        "# Create the LDA model\n",
        "lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=passes)\n",
        "\n",
        "# Display the topics\n",
        "topics = lda.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QCbB1c389rT"
      },
      "source": [
        "The variations in output each time you run an LDA model are due to the stochastic nature of the algorithms used in Latent Dirichlet Allocation. Here are the key reasons for these variations:\n",
        "\n",
        "* Random Initialization: Most LDA implementations (including gensim) start with a random initialization of the topic assignments for each word. This randomness affects the subsequent updates and iterations of the algorithm.\n",
        "\n",
        "* Sampling Methods: LDA often uses sampling methods like Gibbs sampling or variational Bayes inference to estimate the distributions of topics over words and documents. These methods inherently involve randomness, which can lead to different results each time the model is trained, especially if the number of iterations is not large enough to reach convergence.\n",
        "\n",
        "* Convergence Issues: If the LDA model doesn't fully converge due to too few iterations or poor parameter settings (like learning rates), the output may vary significantly between runs. Achieving convergence in probabilistic models can be challenging and might require tuning parameters such as the number of iterations and choosing appropriate hyperparameters (like alpha and beta for LDA).\n",
        "\n",
        "* Number of Topics: The choice of the number of topics (num_topics) can also influence the stability of your topics. Too few or too many topics can lead to overfitting or underfitting, respectively, making the model sensitive to initial conditions or specific samples of data.\n",
        "\n",
        "### Ensuring Consistency\n",
        "\n",
        "To reduce the variability in your LDA models, you can take the following steps:\n",
        "\n",
        "* Set a Random Seed: Most LDA implementations allow you to set a random seed to make the results reproducible. This is done by fixing the seed for the random number generator used by the model.\n",
        "\n",
        "* Increase the Number of Iterations: Allowing more iterations can help the model converge more consistently, which, in turn, makes the output more stable.\n",
        "\n",
        "* Tune Hyperparameters: Adjusting the hyperparameters, such as alpha (document-topic density) and beta (topic-word density), can help in achieving better and more consistent results. These parameters control the sparsity of the topics extracted by the model.\n",
        "\n",
        "* Extensive Preprocessing: More consistent and thorough preprocessing of the text data can lead to less noise in the input, which helps stabilize the output.\n",
        "\n",
        "```\n",
        "lda_model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=10,\n",
        "    random_state=100,\n",
        "    update_every=1,\n",
        "    chunksize=100,\n",
        "    passes=10,\n",
        "    alpha='auto',  # can be set as a scalar like '0.01' or 'auto' for learning the optimal alpha\n",
        "    eta='auto'     # eta is another name for beta in gensim, similarly settable\n",
        ")\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs40G5UJ9EAe"
      },
      "outputs": [],
      "source": [
        "# Set parameters\n",
        "num_topics = 3\n",
        "passes = 10\n",
        "\n",
        "# Create the LDA model\n",
        "lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=passes,random_state=100)\n",
        "\n",
        "# Display the topics\n",
        "topics = lda.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGUq2f7xbu3S"
      },
      "source": [
        "We can also display the topics as wordclouds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDpnJt_ndc5m"
      },
      "outputs": [],
      "source": [
        "%pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JarpWoA-b605"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_wordcloud(model, topic):\n",
        "    text = {word: value for word, value in model.show_topic(topic, 200)}\n",
        "    wc = WordCloud(background_color=\"white\", max_words=1000)\n",
        "    wc.generate_from_frequencies(text)\n",
        "    plt.imshow(wc, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    return plt\n",
        "\n",
        "create_wordcloud(lda, topic=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NMB6kB9Eh3y"
      },
      "source": [
        "##Coherence Score\n",
        "Coherence measures the degree of semantic similarity between high scoring words in the topic. These scores help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4YgR5cYEq8-"
      },
      "outputs": [],
      "source": [
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "coherence_model_lda = CoherenceModel(model=lda, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('Coherence Score:', coherence_lda)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZtrrFSXFM2D"
      },
      "source": [
        "## Number of Topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb9s1BoZFQSZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Range of topics to evaluate\n",
        "topic_range = range(2, 6)\n",
        "\n",
        "# List to store coherence\n",
        "coherence_scores = []\n",
        "\n",
        "for num_topics in topic_range:\n",
        "    lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=passes, random_state=100)\n",
        "    # Initialize CoherenceModel after training the LDA model\n",
        "    coherence_model_lda = CoherenceModel(model=lda, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_lda = coherence_model_lda.get_coherence()\n",
        "\n",
        "    # Append the coherence score\n",
        "    coherence_scores.append(coherence_lda)\n",
        "\n",
        "print(coherence_scores)\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(topic_range, coherence_scores)\n",
        "plt.title(\"Coherence Scores vs Number of Topics\")\n",
        "plt.xlabel(\"Number of Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Select the Final Model"
      ],
      "metadata": {
        "id": "m-YPmI_mHWjS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj4jaS0gEsm4"
      },
      "outputs": [],
      "source": [
        "# Set parameters\n",
        "num_topics = 3\n",
        "passes = 10\n",
        "\n",
        "# Create the LDA model\n",
        "lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=passes,random_state=100)\n",
        "\n",
        "# Display the topics\n",
        "topics = lda.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3t72sS5KYTW"
      },
      "source": [
        "## Top terms for each topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DUJZCKJWgRW"
      },
      "outputs": [],
      "source": [
        "# Print the top 10 terms for each topic\n",
        "for topic_id in range(num_topics):\n",
        "    top_terms = lda.show_topic(topic_id, topn=10)  # Get the top 10 terms for this topic\n",
        "    terms = ', '.join([term for term, _ in top_terms])\n",
        "    print(f\"Topic {topic_id}: {terms}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xk_K_zpWwq3"
      },
      "source": [
        "## Interactive Web-based Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIKw-02BVZif"
      },
      "outputs": [],
      "source": [
        "%pip install pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WzkBgvwVfHA"
      },
      "outputs": [],
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "# Assume `lda` is the LDA model and `corpus` and `dictionary` are your corpus and dictionary from Gensim\n",
        "\n",
        "# Prepare the visualization data\n",
        "vis_data = gensimvis.prepare(lda, corpus, dictionary)\n",
        "\n",
        "# Display the visualization in a Jupyter Notebook (or in an IPython environment)\n",
        "pyLDAvis.display(vis_data)\n",
        "\n",
        "# To save the visualization as an HTML file\n",
        "pyLDAvis.save_html(vis_data, 'lda_visualization.html')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Turn\n",
        "Conduct topic modeling with `sms_spam.csv`and `oct_delta.csv` data."
      ],
      "metadata": {
        "id": "SyuHy2e3PkQw"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}