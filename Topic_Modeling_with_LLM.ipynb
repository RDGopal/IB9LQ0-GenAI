{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfPxIp1UXM80Irh8yPU4ib",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RDGopal/IB9LQ0-GenAI/blob/main/Topic_Modeling_with_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# Topic Modeling with LLM\n",
        "We will read the first 100 rows of the file `Reviews.csv` and conduct topic modeling with a transformer based model from HuggingFace transformers pipeline.\n",
        "\n",
        "We will take a slightly different approach to topic modeling. In this case, we have a list of pre-chosen topics:\n",
        "\n",
        "[\"Fit\", \"Comfort\", \"Material\", \"Quality\", \"Price\", \"Style\", \"Color\", \"Size\", \"Shipping\", \"Customer Service\"]."
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "62Bop-d0nNag"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/RDGopal/IB9LQ0-GenAI/main/Data/Reviews.csv',nrows=100)\n",
        "\n",
        "# Identify NaN values in 'Review' column\n",
        "mask = df['Review'].notnull()\n",
        "\n",
        "# Filter DataFrame using the mask\n",
        "df = df[mask]\n",
        "\n",
        "# Display the updated DataFrame (Optional)\n",
        "display(df.head())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "cwBT3C2rnOsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Data preparation\n",
        "Extract the review text from the 'Review' column of the dataFrame df into a list called review_texts\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "SB3DuR0mnSPS"
      }
    },
    {
      "source": [
        "review_texts = df['Review'].astype(str).tolist()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "OIMEllj_nSu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Data wrangling\n",
        "Clean and preprocess the review texts, including removing irrelevant characters, converting to lowercase, and removing stop words.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "BLEfy20DnWD_"
      }
    },
    {
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords if not already present\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "preprocessed_reviews = []\n",
        "for review in review_texts:\n",
        "    # Clean the text\n",
        "    review = re.sub(r'[^\\w\\s]', '', str(review))  # Remove punctuation and special characters\n",
        "\n",
        "    # Convert to lowercase\n",
        "    review = review.lower()\n",
        "\n",
        "    # Remove stop words\n",
        "    words = review.split()\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    preprocessed_reviews.append(\" \".join(filtered_words))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3588ZNgfnXGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Model training\n",
        "Perform topic modeling using the Hugging Face Transformers pipeline.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "w4S30isWnbn3"
      }
    },
    {
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Create a topic modeling pipeline\n",
        "topic_model = pipeline(task=\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Define candidate topics\n",
        "candidate_labels = [\"Fit\", \"Comfort\", \"Material\", \"Quality\", \"Price\", \"Style\", \"Color\", \"Size\", \"Shipping\", \"Customer Service\"]\n",
        "\n",
        "# Perform topic modeling\n",
        "results = topic_model(preprocessed_reviews, candidate_labels)\n",
        "\n",
        "# Store results in a list of dictionaries (or a DataFrame)\n",
        "topic_modeling_results = []\n",
        "for i, result in enumerate(results):\n",
        "    topic_probabilities = dict(zip(result['labels'], result['scores']))\n",
        "    topic_modeling_results.append({\"review_index\": i, **topic_probabilities})\n",
        "\n",
        "# Display the first few results (optional)\n",
        "print(topic_modeling_results[:5])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Psq2uXeGncp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Data visualization\n",
        "Visualize the topic modeling results.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "cVSFfy6Rqm6N"
      }
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming topic_modeling_results is a list of dictionaries as produced by the previous code block.\n",
        "\n",
        "# Individual review visualizations\n",
        "for i, result in enumerate(topic_modeling_results):\n",
        "    plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "    topics = list(result.keys())\n",
        "    probabilities = list(result.values())\n",
        "\n",
        "    # Remove 'review_index' from topics and probabilities\n",
        "    topics.remove('review_index')\n",
        "    probabilities = probabilities[1:]\n",
        "\n",
        "    plt.bar(topics, probabilities, color=['skyblue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan'])\n",
        "    plt.xlabel(\"Topics\")\n",
        "    plt.ylabel(\"Probability Score\")\n",
        "    plt.title(f\"Topic Probabilities for Review {i}\")\n",
        "    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"review_{i}_topic_probabilities.png\")  # Save each plot\n",
        "    plt.close()  # Close the plot to free up memory\n",
        "\n",
        "\n",
        "# Summary visualization (average probabilities across all reviews)\n",
        "average_probabilities = {}\n",
        "for topic in list(topic_modeling_results[0].keys())[1:]: # Skip the first element 'review_index'\n",
        "    average_probabilities[topic] = sum([result[topic] for result in topic_modeling_results]) / len(topic_modeling_results)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(average_probabilities.keys(), average_probabilities.values(), color=['skyblue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan'])\n",
        "plt.xlabel(\"Topics\")\n",
        "plt.ylabel(\"Average Probability Score\")\n",
        "plt.title(\"Average Topic Probabilities Across All Reviews\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"average_topic_probabilities.png\")\n",
        "plt.show()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "BsW706ivqn8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Summary:\n",
        "\n",
        "The overall goal was to perform topic modeling on customer reviews, so we can infer the implicit question: \"What are the main topics discussed in these customer reviews?\"  The analysis provides probabilities for each review belonging to ten pre-defined topics.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "6dpuTMBkqx-f"
      }
    }
  ]
}